//
//  ViewController.swift
//  roboneko capture v3
//
//  Created by Tomohiko HARADA on 2021/11/03.
//

import UIKit
import SceneKit
import ARKit
import CoreLocation
import AssetsLibrary

class ViewController: UIViewController, ARSCNViewDelegate, ARSessionDelegate, CLLocationManagerDelegate {

    @IBOutlet var sceneView: ARSCNView!
    @IBOutlet weak var UILabel1: UILabel!
    @IBOutlet weak var UISwitch1: UISwitch!

    private var supportedVideoFormats: [ARConfiguration.VideoFormat]!
    private var output: OutputStream!
    private var locationManager: CLLocationManager!
    private var latitude: String = ""
    private var longitude: String = ""
    private var outputDirURL: URL!
    private var isRecording = false

    let userDefaults = UserDefaults.standard
    @IBAction func switchChanged(_ sender: UISwitch) {
        isRecording = sender.isOn
        userDefaults.set(sender.isOn, forKey: "Key1")
    }

    override func viewDidLoad() {
        super.viewDidLoad()
        
        // Set the view's delegate
        sceneView.delegate = self

        // Show statistics such as fps and timing information
        sceneView.showsStatistics = true

//        // Create a new scene
//        let scene = SCNScene(named: "art.scnassets/ship.scn")!
//        sceneView.debugOptions = ARSCNDebugOptions.showFeaturePoints
//
//        // Set the scene to the view
//        sceneView.scene = scene

        // *** by haradatm
        sceneView.session.delegate = self
        sceneView.preferredFramesPerSecond = 30
        sceneView.automaticallyUpdatesLighting = false
        locationManager = CLLocationManager()
        locationManager.delegate = self
        locationManager.requestWhenInUseAuthorization()
        locationManager.startUpdatingLocation()
        isRecording = false
        userDefaults.set(isRecording, forKey: "Key1")
        UISwitch1.isOn = userDefaults.bool(forKey: "Key1")
        // *** by haradatm
    }
    
    override func viewWillAppear(_ animated: Bool) {
        super.viewWillAppear(animated)

        // Create a session configuration
        let configuration = ARWorldTrackingConfiguration()
        configuration.isLightEstimationEnabled = true


        // *** by haradatm
        UIApplication.shared.isIdleTimerDisabled = true

        let formats = ARWorldTrackingConfiguration.supportedVideoFormats
        for format in formats {
            if (format.imageResolution.width == 1920.0 && format.imageResolution.height == 1080.0) {
                configuration.videoFormat = format
                print(format)
            }
        }

        guard let documentURL = FileManager.default.urls(for: .documentDirectory, in: .userDomainMask).first else { return }
        let dateFormatter = DateFormatter()
        dateFormatter.dateFormat = "yyyy-MM-dd-HH-mm-ss-SSS"
        outputDirURL = documentURL.appendingPathComponent(dateFormatter.string(from: Date()))

        do {
            try FileManager.default.createDirectory(at: outputDirURL, withIntermediateDirectories: true)
        } catch {
            print(error)
        }

        let header =
            "timestamp," +
            "Camera.fx," +
            "Camera.fy," +
            "Camera.ox," +
            "Camera.oy," +
            "rotation(0:0)," +
            "rotation(0:1)," +
            "rotation(0:2)," +
            "rotation(1:0)," +
            "rotation(1:1)," +
            "rotation(1:2)," +
            "rotation(2:0)," +
            "rotation(2:1)," +
            "rotation(2:2)," +
            "rotation(3:0)," +
            "rotation(3:1)," +
            "rotation(3:2)," +
            "transform(x)," +
            "transform(y)," +
            "transform(z)," +
            "exposureDuration," +
            "exposureOffset," +
            "width," +
            "height," +
            "lightEstimate," +
            "latitude," +
            "longitude\n"

        let filename = outputDirURL.appendingPathComponent("camera.txt")
        guard let outputStream = OutputStream(url: filename, append: true) else {return}
        outputStream.open()
        defer { outputStream.close() }
        guard let data = header.data(using: .utf8) else {return}
        data.withUnsafeBytes({
            let unsafeBufferPtr = $0.bindMemory(to: UInt8.self)
            if let unsafePtr = unsafeBufferPtr.baseAddress {
                _ = outputStream.write(unsafePtr, maxLength: $0.count)
            }
        })
        // *** by haradatm

        
        // Run the view's session
        sceneView.session.run(configuration)
    }
    
    override func viewWillDisappear(_ animated: Bool) {
        super.viewWillDisappear(animated)

        
        // *** by haradatm
        UIApplication.shared.isIdleTimerDisabled = false

        isRecording = false
        userDefaults.set(isRecording, forKey: "Key1")
        UISwitch1.isOn = userDefaults.bool(forKey: "Key1")
        // *** by haradatm

        
        // Pause the view's session
        sceneView.session.pause()
    }

//    // MARK: - ARSCNViewDelegate
//
///*
//    // Override to create and configure nodes for anchors added to the view's session.
//    func renderer(_ renderer: SCNSceneRenderer, nodeFor anchor: ARAnchor) -> SCNNode? {
//        let node = SCNNode()
//
//        return node
//    }
//*/
//
//    func session(_ session: ARSession, didFailWithError error: Error) {
//        // Present an error message to the user
//
//    }
//
//    func sessionWasInterrupted(_ session: ARSession) {
//        // Inform the user that the session has been interrupted, for example, by presenting an overlay
//
//    }
//
//    func sessionInterruptionEnded(_ session: ARSession) {
//        // Reset tracking and/or remove existing anchors if consistent tracking is required
//
//    }

    func session(_ session: ARSession, didUpdate frame: ARFrame) {
        let currentFrame = sceneView.session.currentFrame
        let camera = currentFrame?.camera
        let time = Int64(currentFrame!.timestamp * 1000)

        if (currentFrame != nil) {

            let msg =
                " timestamp: \(currentFrame?.timestamp ?? 0)\n" +
                " Camera.fx: \(camera?.intrinsics.columns.0.x ?? 0)\n" +
                " Camera.fy: \(camera?.intrinsics.columns.1.y ?? 0)\n" +
                " Camera.ox: \(camera?.intrinsics.columns.2.x ?? 0)\n" +
                " Camera.oy: \(camera?.intrinsics.columns.2.y ?? 0)\n" +
                " transform.x: \(camera?.transform.columns.3.x ?? 0)\n" +
                " transform.y: \(camera?.transform.columns.3.y ?? 0)\n" +
                " transform.z: \(camera?.transform.columns.3.z ?? 0)\n" +
                " exposureDuration: \(camera?.exposureDuration ?? 0)\n" +
                " exposureOffset:   \(camera?.exposureOffset ?? 0)\n" +
                " width:  \(camera?.imageResolution.width ?? 0)\n" +
                " height: \(camera?.imageResolution.height ?? 0)\n" +
                " latitude:  \(String(self.latitude))\n" +
                " longitude: \(String(self.longitude))\n" +
                " isRecording: \(String(self.isRecording))\n"
            self.UILabel1.text = msg

            if (isRecording) {

                DispatchQueue.global(qos: .userInitiated).async {

                    let text =
                        "\(time)," +
                        "\(camera?.intrinsics.columns.0.x ?? 0)," +
                        "\(camera?.intrinsics.columns.1.y ?? 0)," +
                        "\(camera?.intrinsics.columns.2.x ?? 0)," +
                        "\(camera?.intrinsics.columns.2.y ?? 0)," +
                        "\(camera?.transform.columns.0.x ?? 0)," +
                        "\(camera?.transform.columns.1.x ?? 0)," +
                        "\(camera?.transform.columns.2.x ?? 0)," +
                        "\(camera?.transform.columns.0.y ?? 0)," +
                        "\(camera?.transform.columns.1.y ?? 0)," +
                        "\(camera?.transform.columns.2.y ?? 0)," +
                        "\(camera?.transform.columns.0.z ?? 0)," +
                        "\(camera?.transform.columns.1.z ?? 0)," +
                        "\(camera?.transform.columns.2.z ?? 0)," +
                        "\(camera?.transform.columns.0.w ?? 0)," +
                        "\(camera?.transform.columns.1.w ?? 0)," +
                        "\(camera?.transform.columns.2.w ?? 0)," +
                        "\(camera?.transform.columns.3.x ?? 0)," +
                        "\(camera?.transform.columns.3.y ?? 0)," +
                        "\(camera?.transform.columns.3.z ?? 0)," +
                        "\(camera?.exposureDuration ?? 0)," +
                        "\(camera?.exposureOffset ?? 0)," +
                        "\(camera?.imageResolution.width ?? 0)," +
                        "\(camera?.imageResolution.height ?? 0)," +
                        "\(currentFrame?.lightEstimate?.ambientIntensity ?? 0)," +
                        "\(String(self.latitude))," +
                        "\(String(self.longitude))\n"

                    let filename = self.outputDirURL.appendingPathComponent("camera.txt")
                    guard let outputStream = OutputStream(url: filename, append: true) else {return}
                    outputStream.open()
                    defer { outputStream.close() }
                    guard let data = text.data(using: .utf8) else {return}
                    data.withUnsafeBytes({
                        let unsafeBufferPtr = $0.bindMemory(to: UInt8.self)
                        if let unsafePtr = unsafeBufferPtr.baseAddress {
                            _ = outputStream.write(unsafePtr, maxLength: $0.count)
                        }
                    })

                }

                DispatchQueue.global(qos: .userInitiated).async {

                    guard let capturedImage = currentFrame?.capturedImage else {return}
                    let ciImageDepth = CIImage(cvPixelBuffer: capturedImage)
                    let contextDepth:CIContext = CIContext.init(options: nil)
                    let cgImageDepth:CGImage = contextDepth.createCGImage(ciImageDepth, from: ciImageDepth.extent)!
                    let uiImageDepth:UIImage = UIImage(cgImage: cgImageDepth, scale: 0, orientation: .right)
                    let pngImageData = uiImageDepth.pngData()

                    let filename = self.outputDirURL.appendingPathComponent(String(format: "%d", time) + ".png")
                    print(filename)
                    do {
                        try pngImageData!.write(to: filename, options: .atomic)
                    } catch {
                        print(error)
                    }
                }
            }
        }
    }

    func locationManager(_ manager: CLLocationManager, didUpdateLocations locations: [CLLocation]) {
        let location = locations.first
        let latitude = location?.coordinate.latitude
        let longitude = location?.coordinate.longitude
        self.latitude = String(latitude!)
        self.longitude = String(longitude!)
    }

}
